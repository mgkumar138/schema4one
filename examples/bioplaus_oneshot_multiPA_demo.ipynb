{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo to replicate the one-shot learning behaviour demonstrated by rats using a fully neural implementation of schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import time\n",
    "sys.path.append(\"C:/Users/Razer/PycharmProjects/schema4one/examples/\")\n",
    "from demo_utils import run_hebagent_multiplepa_expt, get_default_hp, Maze, ResACAgent\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6pa_res_0.8cb_5e-05ach_7.5e-06glr_Truesl_0.0002clr_3000tg_5e-05alr_5R_20dt_181364.437\n"
     ]
    }
   ],
   "source": [
    "hp = get_default_hp(task='6pa')\n",
    "\n",
    "hp['time'] = 600  # set max time for each trial\n",
    "hp['probetime'] = 60  # set max time for each probe trial\n",
    "\n",
    "hp['alr'] = 0.00005  # acor learning rate\n",
    "hp['clr'] = 0.0002  # critic learning rate\n",
    "hp['taug'] = 3000  # time constant for RPE\n",
    "hp['usenmc'] = True  # True to use Neural Motor Controller\n",
    "hp['stochlearn'] = True  # True to learn association in one-shot using node perturbation method\n",
    "hp['Rval'] = 5  # reward value\n",
    "hp['render'] = False  # visualise movement trial by trial\n",
    "hp['contbeta'] = 0.8  # Beta control parameter where Actor and Schema determines direction of movement\n",
    "\n",
    "hp['exptname'] = '6pa_res_{}cb_{}ach_{}glr_{}sl_{}clr_{}tg_{}alr_{}R_{}dt_{}'.format(\n",
    "    hp['contbeta'],hp['ach'], hp['glr'], hp['stochlearn'], hp['clr'], hp['taug'],hp['alr'],\n",
    "    hp['Rval'], hp['tstep'], time.monotonic())\n",
    "print(hp['exptname'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Environments\n",
    "- OPA: 20 session - 17 training, 3 probes\n",
    "- 2NPA, 6NPA or NM 2 sessions: 1 training, 1 probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Maze(hp)\n",
    "trainprobesess = [2,9,16]\n",
    "oneshotprobesess = [2]\n",
    "envtypes = ['train','opa','2npa','6npa','nm','6nm']\n",
    "probenames = ['PS1','PS2','PS3']\n",
    "evalprobenames = ['OPA','2NPA','6NPA','NM']\n",
    "nmprobenames = ['NM1','NM2','NM3', '6NPANM']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize neural agent with neural motor controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ResACAgent(hp=hp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Neural agent on OPA for 20 sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train env created. Training ...\n",
      "C4 | S 90 | Dgr 0 | Recall Goal [-0.02 -0.14  0.98]\n",
      "C5 | S 132 | Dgr 0 | Recall Goal [-0.04 -0.01  1.11]\n",
      "C1 | S 53 | Dgr 0 | Recall Goal [-0.07 -0.03  1.02]\n",
      "C3 | S 34 | Dgr 0 | Recall Goal [-0.05 -0.1   1.07]\n",
      "C2 | S 131 | Dgr 0 | Recall Goal [0.06 0.01 1.09]\n",
      "C6 | S 120 | Dgr 0 | Recall Goal [ 0.01 -0.26  1.02]\n",
      "############## train Session 1/20, Avg Steps 4705.8, ##############\n",
      "C5 | S 60 | Dgr 10.5 | Recall Goal [-0.07 -0.06  0.82]\n",
      "C2 | S 60 | Dgr 5.44 | Recall Goal [ 0.07 -0.1   0.74]\n",
      "C6 | S 60 | Dgr 0 | Recall Goal [-0.07 -0.19  0.78]\n"
     ]
    }
   ],
   "source": [
    "mpalatency, mpapath, mpaweights, mpavisitratio, mpalearned = run_hebagent_multiplepa_expt(mtype='train', env=env, agent=agent, sessions=20, noreward=trainprobesess, useweight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning performance\n",
    "plt.figure()\n",
    "plt.plot(mpalatency)\n",
    "\n",
    "df = pd.DataFrame(mpavisitratio, index=probenames)\n",
    "ax = df.plot(kind='bar',legend=False)\n",
    "ax.axhline(y=100/6,color='red',linestyle='--')  # chance performance 1 of 6 correct targets\n",
    "ax.set_ylim(0,100)\n",
    "ax.set_ylabel('Visit Ratio')\n",
    "\n",
    "col = ['b', 'g', 'r', 'y', 'm', 'k']\n",
    "env.make('train')\n",
    "f,axs = plt.subplots(nrows=3, ncols=6, figsize=(12,8))\n",
    "for ax in axs.flatten():\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "for p in range(3):\n",
    "    for c in range(6):\n",
    "        K = mpapath[p,c]\n",
    "        ax = axs[p,c]\n",
    "        if p == 0:\n",
    "            ax.set_title(f\"Cue {c+1}\")\n",
    "        if c == 0:\n",
    "            ax.set_ylabel(probenames[p])\n",
    "\n",
    "        ax.axis((-env.au / 2, env.au / 2, -env.au / 2, env.au / 2))\n",
    "        ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "        for r in range(6):\n",
    "            circle = plt.Circle(env.rlocs[r], env.rrad, color=col[r], zorder=3)\n",
    "            ax.add_artist(circle)\n",
    "\n",
    "        ax.plot(K[:, 0], K[:, 1], col[c], alpha=0.5, zorder=2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use trained agent to learn new PAs in one-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Neural agent on OPA for 1 session as control and probe after, use weights learned over 20 sessions on MPA\n",
    "opalatency, opapath, opaweights, opavisitratio, opalearned = run_hebagent_multiplepa_expt(mtype='opa', env=env, agent=agent, sessions=2, noreward=oneshotprobesess, useweight=mpaweights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Neural agent on 2NPA for 1 session and probe after, use weights learned over 20 sessions on MPA\n",
    "npa2latency, npa2path, npa2weights, npa2visitratio, npa2learned = run_hebagent_multiplepa_expt(mtype='2npa', env=env, agent=agent, sessions=2, noreward=oneshotprobesess, useweight=mpaweights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Neural agent on 6NPA for 1 session and probe after, use weights learned over 20 sessions on MPA\n",
    "npa6latency, npa6path, npa6weights, npa6visitratio, npa6learned = run_hebagent_multiplepa_expt(mtype='6npa', env=env, agent=agent, sessions=2, noreward=oneshotprobesess, useweight=mpaweights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Neural agent on NM for 1 session and probe after, use weights learned over 20 sessions on MPA\n",
    "nmlatency, nmpath, nmweights, nmvisitratio, nmlearned = run_hebagent_multiplepa_expt(mtype='nm', env=env, agent=agent, sessions=2, noreward=oneshotprobesess, useweight=mpaweights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot performance\n",
    "evaldigrate = np.concatenate([opavisitratio, npa2visitratio, npa6visitratio, nmvisitratio])\n",
    "print(evaldigrate)\n",
    "\n",
    "df2 = pd.DataFrame(evaldigrate, index=evalprobenames)\n",
    "ax = df2.plot(kind='bar',legend=False)\n",
    "ax.axhline(y=100/6,color='red',linestyle='--')  # chance performance 1 of 6 correct targets\n",
    "ax.set_ylim(0,100)\n",
    "ax.set_ylabel('Visit Ratio')\n",
    "\n",
    "\n",
    "col = ['b', 'g', 'r', 'y', 'm', 'k']\n",
    "allevalpaths = [opapath, npa2path, npa6path, nmpath]\n",
    "npa2cues = [7, 2,3,4,5,8]\n",
    "f,axs = plt.subplots(nrows=4, ncols=6, figsize=(12,8))\n",
    "for ax in axs.flatten():\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "for p in range(4):\n",
    "    env.make(envtypes[p+1])\n",
    "    for c in range(6):\n",
    "        path = allevalpaths[p]\n",
    "        K = path[0, c]\n",
    "        ax = axs[p,c]\n",
    "        if p == 0:\n",
    "            ax.set_title(f\"Cue {c+1}\")\n",
    "        elif p == 1:\n",
    "            ax.set_title(f\"Cue {npa2cues[c]}\")\n",
    "        else:\n",
    "            ax.set_title(f\"Cue {c+11}\")\n",
    "\n",
    "        if c == 0:\n",
    "            ax.set_ylabel(evalprobenames[p])\n",
    "\n",
    "        ax.axis((-env.au / 2, env.au / 2, -env.au / 2, env.au / 2))\n",
    "        ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "        for r in range(6):\n",
    "            circle = plt.Circle(env.rlocs[r], env.rrad, color=col[r], zorder=3)\n",
    "            ax.add_artist(circle)\n",
    "\n",
    "        ax.plot(K[:, 0], K[:, 1], col[c], alpha=0.5, zorder=2)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduce trained agents to a New Maze (Remap place cells) for 20 sessions followed by 2 sessions with 6 new PAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Neural agent on NM for 20 session similar to on MPA, use weights learned over 20 sessions on MPA\n",
    "nm20latency, nm20path, nm20weights, nm20visitratio, nm20learned = run_hebagent_multiplepa_expt(mtype='nm', env=env, agent=agent, sessions=20, noreward=trainprobesess, useweight=mpaweights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Neural agent on 6NM for 2 session, use weights learned over 20 sessions on NM\n",
    "nm6latency, nm6path, nm6weights, nm6visitratio, nm6learned = run_hebagent_multiplepa_expt(mtype='6nm', env=env, agent=agent, sessions=2, noreward=oneshotprobesess, useweight=nm20weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot relearning new environment and one shot performance\n",
    "# plot performance\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(nm20latency)\n",
    "\n",
    "nmvisitratios = np.concatenate([nm20visitratio, nm6visitratio])\n",
    "df3 = pd.DataFrame(nmvisitratios, index=nmprobenames)\n",
    "df3.plot(kind='bar',legend=False)\n",
    "ax.axhline(y=100/6,color='red',linestyle='--')  # chance performance 1 of 6 correct targets\n",
    "ax.set_ylim(0,100)\n",
    "ax.set_ylabel('Visit Ratio')\n",
    "\n",
    "\n",
    "col = ['b', 'g', 'r', 'y', 'm', 'k']\n",
    "allnmpaths = [nm20path, nm6path]\n",
    "nm6cues = [7,8,9,10,17,18]\n",
    "f,axs = plt.subplots(nrows=4, ncols=6, figsize=(12,8))\n",
    "for ax in axs.flatten():\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "for p in range(4):\n",
    "    if p == 3:\n",
    "        env.make('6nm')\n",
    "    else:\n",
    "        env.make('nm')\n",
    "\n",
    "    for c in range(6):\n",
    "        ax = axs[p,c]\n",
    "        if p == 3:\n",
    "            ax.set_title(f\"Cue {nm6cues[c]}\")\n",
    "            path = allnmpaths[1]\n",
    "            K = path[0, c]\n",
    "        else:\n",
    "            ax.set_title(f\"Cue {c+11}\")\n",
    "            path = allnmpaths[0]\n",
    "            K = path[p, c]\n",
    "\n",
    "        if c == 0:\n",
    "            ax.set_ylabel(nmprobenames[p])\n",
    "\n",
    "        ax.axis((-env.au / 2, env.au / 2, -env.au / 2, env.au / 2))\n",
    "        ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "        for r in range(6):\n",
    "            circle = plt.Circle(env.rlocs[r], env.rrad, color=col[r], zorder=3)\n",
    "            ax.add_artist(circle)\n",
    "\n",
    "        ax.plot(K[:, 0], K[:, 1], col[c], alpha=0.5, zorder=2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
