{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import time\n",
    "sys.path.append(\"C:/Users/Razer/PycharmProjects/schema4one/examples/\")\n",
    "from demo_utils import run_hebagent_multiplepa_expt, get_default_hp, Maze, ResACAgent\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'matplotlib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1740/1322609955.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_default_hp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'6pa'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m  \u001b[1;31m# set max time for each trial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'probetime'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m  \u001b[1;31m# set max time for each probe trial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\schema4one\\examples\\demo_utils.py\u001b[0m in \u001b[0;36mget_default_hp\u001b[1;34m(task, platform)\u001b[0m\n\u001b[0;32m    538\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'platform'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'laptop'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 540\u001b[1;33m         \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Agg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    541\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CUDA_VISIBLE_DEVICES'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'-1'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m         \u001b[0mhp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cpucount'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'matplotlib' is not defined"
     ]
    }
   ],
   "source": [
    "hp = get_default_hp(task='6pa')\n",
    "\n",
    "hp['time'] = 1  # set max time for each trial\n",
    "hp['probetime'] = 2  # set max time for each probe trial\n",
    "\n",
    "hp['alr'] = 0.00005  # acor learning rate\n",
    "hp['clr'] = 0.0002  # critic learning rate\n",
    "hp['taug'] = 3000  # time constant for RPE\n",
    "hp['usenmc'] = True  # True to use Neural Motor Controller\n",
    "hp['stochlearn'] = True  # True to learn association in one-shot using node perturbation method\n",
    "hp['Rval'] = 5  # reward value\n",
    "hp['render'] = False  # visualise movement trial by trial\n",
    "hp['contbeta'] = 0.8  # Beta control parameter where Actor and Schema determines direction of movement\n",
    "\n",
    "hp['exptname'] = '6pa_res_{}cb_{}ach_{}glr_{}sl_{}clr_{}tg_{}alr_{}R_{}dt_{}'.format(\n",
    "    hp['contbeta'],hp['ach'], hp['glr'], hp['stochlearn'], hp['clr'], hp['taug'],hp['alr'],\n",
    "    hp['Rval'], hp['tstep'], time.monotonic())\n",
    "print(hp['exptname'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize Environments\n",
    "- OPA: 20 session - 17 training, 3 probes\n",
    "- 2NPA, 6NPA or NM 2 sessions: 1 training, 1 probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Maze(hp)\n",
    "trainprobesess = [2,9,16]\n",
    "oneshotprobesess = [2]\n",
    "envtypes = ['train','opa','2npa','6npa','nm','6nm']\n",
    "probenames = ['PS1','PS2','PS3']\n",
    "evalprobenames = ['OPA','2NPA','6NPA','NM']\n",
    "nmprobenames = ['NM1','NM2','NM3', '6NPANM']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize neural agent with neural motor controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ResACAgent(hp=hp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Neural agent on OPA for 20 sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train env created. Training ...\n",
      "C2 | S 30 | Dgr 0 | Recall Goal [-0.12  0.    1.07]\n",
      "C1 | S 78 | Dgr 0 | Recall Goal [ 0.02 -0.04  0.97]\n",
      "C6 | S 274 | Dgr 0 | Recall Goal [-0.14 -0.12  1.02]\n",
      "C4 | S 16 | Dgr 0 | Recall Goal [-0.1  -0.1   0.87]\n",
      "C5 | S 512 | Dgr 0 | Recall Goal [-0.1   0.03  1.  ]\n",
      "C3 | S 105 | Dgr 0 | Recall Goal [ 0.16 -0.06  0.88]\n",
      "############## train Session 1/20, Avg Steps 8471.8, ##############\n",
      "C6 | S 60 | Dgr 0 | Recall Goal [-0.11 -0.11  1.02]\n",
      "C2 | S 60 | Dgr 0 | Recall Goal [-0.05 -0.08  0.77]\n",
      "C3 | S 60 | Dgr 31.9 | Recall Goal [0.01 0.03 0.71]\n",
      "C4 | S 60 | Dgr 72.5 | Recall Goal [-0.02 -0.09  0.8 ]\n",
      "C1 | S 60 | Dgr 54 | Recall Goal [-0.02  0.    1.01]\n",
      "C5 | S 60 | Dgr 0 | Recall Goal [-0.01  0.02  0.6 ]\n",
      "############## train Session 2/20, Avg Steps   nan, ##############\n",
      "C5 | S 353 | Dgr 0 | Recall Goal [-0.25 -0.15  0.98]\n",
      "C3 | S 7 | Dgr 0 | Recall Goal [0.33 0.03 0.97]\n",
      "C2 | S 600 | Dgr 0 | Recall Goal [ 0.   -0.02  0.66]\n",
      "C6 | S 600 | Dgr 0 | Recall Goal [-0.03 -0.07  0.83]\n",
      "C1 | S 92 | Dgr 0 | Recall Goal [-0.3   0.47  1.03]\n",
      "C4 | S 64 | Dgr 0 | Recall Goal [ 0.1  -0.65  1.  ]\n",
      "############## train Session 3/20, Avg Steps 14310.5, ##############\n",
      "C2 | S 600 | Dgr 0 | Recall Goal [-0.05 -0.02  0.44]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_33120/4197644062.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Train Neural agent on OPA for 20 sessions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmpalatency\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmpapath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmpaweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmpavisitratio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmpalearned\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_hebagent_multiplepa_expt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoreward\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainprobesess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0museweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Razer\\PycharmProjects\\schema4one\\examples\\model_np.py\u001b[0m in \u001b[0;36mrun_hebagent_multiplepa_expt\u001b[1;34m(mtype, env, agent, sessions, noreward, useweight)\u001b[0m\n",
      "\u001b[1;32mC:/Users/Razer/PycharmProjects/schema4one\\backend\\model.py\u001b[0m in \u001b[0;36msee\u001b[1;34m(self, state, cue, startbox)\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[0mI\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpcact\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcue\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0mrfr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mI\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcpc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrfr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:/Users/Razer/PycharmProjects/schema4one\\backend\\model.py\u001b[0m in \u001b[0;36mprocess\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[0mI\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwin\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# get input current\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[0mrj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresrecact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrec\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# get recurrent activity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[0mrsig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnrnn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecns\u001b[0m  \u001b[1;31m# white noise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrx\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mI\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrj\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrsig\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# new membrane potential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Razer\\miniconda3\\envs\\s4o\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Razer\\miniconda3\\envs\\s4o\\lib\\site-packages\\tensorflow\\python\\ops\\random_ops.py\u001b[0m in \u001b[0;36mrandom_normal\u001b[1;34m(shape, mean, stddev, dtype, seed, name)\u001b[0m\n\u001b[0;32m     95\u001b[0m         shape_tensor, dtype, seed=seed1, seed2=seed2)\n\u001b[0;32m     96\u001b[0m     \u001b[0mmul\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mstddev_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m     \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m     \u001b[0mtensor_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaybe_set_static_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Razer\\miniconda3\\envs\\s4o\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m    372\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m--> 374\u001b[1;33m         _ctx, \"Add\", name, x, y)\n\u001b[0m\u001b[0;32m    375\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mpalatency, mpapath, mpaweights, mpavisitratio, mpalearned = run_hebagent_multiplepa_expt(mtype='train', env=env, agent=agent, sessions=20, noreward=trainprobesess, useweight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot learning performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(mpalatency)\n",
    "\n",
    "df = pd.DataFrame(mpavisitratio, index=probenames)\n",
    "ax = df.plot(kind='bar',legend=False)\n",
    "ax.axhline(y=100/6,color='red',linestyle='--')  # chance performance 1 of 6 correct targets\n",
    "ax.set_ylim(0,100)\n",
    "ax.set_ylabel('Visit Ratio')\n",
    "\n",
    "col = ['b', 'g', 'r', 'y', 'm', 'k']\n",
    "env.make('train')\n",
    "f,axs = plt.subplots(nrows=3, ncols=6, figsize=(12,8))\n",
    "for ax in axs.flatten():\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "for p in range(3):\n",
    "    for c in range(6):\n",
    "        K = mpapath[p,c]\n",
    "        ax = axs[p,c]\n",
    "        if p == 0:\n",
    "            ax.set_title(f\"Cue {c+1}\")\n",
    "        if c == 0:\n",
    "            ax.set_ylabel(probenames[p])\n",
    "\n",
    "        ax.axis((-env.au / 2, env.au / 2, -env.au / 2, env.au / 2))\n",
    "        ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "        for r in range(6):\n",
    "            circle = plt.Circle(env.rlocs[r], env.rrad, color=col[r], zorder=3)\n",
    "            ax.add_artist(circle)\n",
    "\n",
    "        ax.plot(K[:, 0], K[:, 1], col[c], alpha=0.5, zorder=2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Neural agent on OPA for 1 session as control and probe after, use weights learned over 20 sessions on MPA\n",
    "opalatency, opapath, opaweights, opavisitratio, opalearned = run_hebagent_multiplepa_expt(mtype='opa', env=env, agent=agent, sessions=2, noreward=oneshotprobesess, useweight=mpaweights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Neural agent on 2NPA for 1 session and probe after, use weights learned over 20 sessions on MPA\n",
    "npa2latency, npa2path, npa2weights, npa2visitratio, npa2learned = run_hebagent_multiplepa_expt(mtype='2npa', env=env, agent=agent, sessions=2, noreward=oneshotprobesess, useweight=mpaweights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Neural agent on 6NPA for 1 session and probe after, use weights learned over 20 sessions on MPA\n",
    "npa6latency, npa6path, npa6weights, npa6visitratio, npa6learned = run_hebagent_multiplepa_expt(mtype='6npa', env=env, agent=agent, sessions=2, noreward=oneshotprobesess, useweight=mpaweights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Neural agent on NM for 1 session and probe after, use weights learned over 20 sessions on MPA\n",
    "nmlatency, nmpath, nmweights, nmvisitratio, nmlearned = run_hebagent_multiplepa_expt(mtype='nm', env=env, agent=agent, sessions=2, noreward=oneshotprobesess, useweight=mpaweights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot performance\n",
    "evaldigrate = np.concatenate([opavisitratio, npa2visitratio, npa6visitratio, nmvisitratio])\n",
    "print(evaldigrate)\n",
    "\n",
    "df2 = pd.DataFrame(evaldigrate, index=evalprobenames)\n",
    "ax = df2.plot(kind='bar',legend=False)\n",
    "ax.axhline(y=100/6,color='red',linestyle='--')  # chance performance 1 of 6 correct targets\n",
    "ax.set_ylim(0,100)\n",
    "ax.set_ylabel('Visit Ratio')\n",
    "\n",
    "\n",
    "col = ['b', 'g', 'r', 'y', 'm', 'k']\n",
    "allevalpaths = [opapath, npa2path, npa6path, nmpath]\n",
    "npa2cues = [7, 2,3,4,5,8]\n",
    "f,axs = plt.subplots(nrows=4, ncols=6, figsize=(12,8))\n",
    "for ax in axs.flatten():\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "for p in range(4):\n",
    "    env.make(envtypes[p+1])\n",
    "    for c in range(6):\n",
    "        path = allevalpaths[p]\n",
    "        K = path[0, c]\n",
    "        ax = axs[p,c]\n",
    "        if p == 0:\n",
    "            ax.set_title(f\"Cue {c+1}\")\n",
    "        elif p == 1:\n",
    "            ax.set_title(f\"Cue {npa2cues[c]}\")\n",
    "        else:\n",
    "            ax.set_title(f\"Cue {c+11}\")\n",
    "\n",
    "        if c == 0:\n",
    "            ax.set_ylabel(evalprobenames[p])\n",
    "\n",
    "        ax.axis((-env.au / 2, env.au / 2, -env.au / 2, env.au / 2))\n",
    "        ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "        for r in range(6):\n",
    "            circle = plt.Circle(env.rlocs[r], env.rrad, color=col[r], zorder=3)\n",
    "            ax.add_artist(circle)\n",
    "\n",
    "        ax.plot(K[:, 0], K[:, 1], col[c], alpha=0.5, zorder=2)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Neural agent on NM for 20 session similar to on MPA, use weights learned over 20 sessions on MPA\n",
    "nm20latency, nm20path, nm20weights, nm20visitratio, nm20learned = run_hebagent_multiplepa_expt(mtype='nm', env=env, agent=agent, sessions=20, noreward=trainprobesess, useweight=mpaweights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Neural agent on 6NM for 2 session, use weights learned over 20 sessions on NM\n",
    "nm6latency, nm6path, nm6weights, nm6visitratio, nm6learned = run_hebagent_multiplepa_expt(mtype='6nm', env=env, agent=agent, sessions=2, noreward=oneshotprobesess, useweight=nm20weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot relearning new environment and one shot performance\n",
    "# plot performance\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(nm20latency)\n",
    "\n",
    "nmvisitratios = np.concatenate([nm20visitratio, nm6visitratio])\n",
    "df3 = pd.DataFrame(nmvisitratios, index=nmprobenames)\n",
    "df3.plot(kind='bar',legend=False)\n",
    "ax.axhline(y=100/6,color='red',linestyle='--')  # chance performance 1 of 6 correct targets\n",
    "ax.set_ylim(0,100)\n",
    "ax.set_ylabel('Visit Ratio')\n",
    "\n",
    "\n",
    "col = ['b', 'g', 'r', 'y', 'm', 'k']\n",
    "allnmpaths = [nm20path, nm6path]\n",
    "nm6cues = [7,8,9,10,17,18]\n",
    "f,axs = plt.subplots(nrows=4, ncols=6, figsize=(12,8))\n",
    "for ax in axs.flatten():\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "for p in range(4):\n",
    "    if p == 3:\n",
    "        env.make('6nm')\n",
    "    else:\n",
    "        env.make('nm')\n",
    "\n",
    "    for c in range(6):\n",
    "        ax = axs[p,c]\n",
    "        if p == 3:\n",
    "            ax.set_title(f\"Cue {nm6cues[c]}\")\n",
    "            path = allnmpaths[1]\n",
    "            K = path[0, c]\n",
    "        else:\n",
    "            ax.set_title(f\"Cue {c+11}\")\n",
    "            path = allnmpaths[0]\n",
    "            K = path[p, c]\n",
    "\n",
    "        if c == 0:\n",
    "            ax.set_ylabel(nmprobenames[p])\n",
    "\n",
    "        ax.axis((-env.au / 2, env.au / 2, -env.au / 2, env.au / 2))\n",
    "        ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "        for r in range(6):\n",
    "            circle = plt.Circle(env.rlocs[r], env.rrad, color=col[r], zorder=3)\n",
    "            ax.add_artist(circle)\n",
    "\n",
    "        ax.plot(K[:, 0], K[:, 1], col[c], alpha=0.5, zorder=2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
